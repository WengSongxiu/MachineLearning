# 条件随机场CRF

条件随机场(conditional random field, CRF)是用来**标注和划分序列结构数据**的**概率化结构模型**。言下之意，就是对于给定的输出，标识序列Y和观测序列X，条件随机场通过定义**条件概率P(Y|X)**，而不是联合概率分布P(X, Y)来描述模型。从定义中看出：CRF考虑一件东西，不但要考虑自身，还要考虑周围的情况。举个例子，我们做命名实体识别，例句：“Google的总部在硅谷”。我们知道地址是“硅谷”，其他位置的词对我们识别“硅谷”有啥帮助呢？例如，“硅谷”前面是“在”，是不是这个字后面经常接地址呢？“在”前面的词是不是应该是名词？这样的综合考虑，就是CRF中的特征选择或者叫特征模板。简要的说，CRF算法，需要解决三个问题：

- 特征的选择。在CRF中，很重要的工作就是找特征函数，然后利用特征函数来构建特征方程。在自然语言处理领域，
  $$
  特征函数主要是指一个句子s，词在句子中的位置i，当前词的标签l_i，前一个词的标签l_{i−1}
  $$
- **参数训练**。在每一个特征函数之前，都有一个参数，也就是训练它们的**权重**。CRF的参数训练，可以采用**梯度下降法**。

- **解码**。解码问题，如果来一个句子，遍历所有可能的分割，会导致计算量过大。因此，可以采用类似**viterbi**这样的**动态规划**算法，来提高效率。

## 概率图模型

概率模型是将学习任务归结为计算变量的概率分布的模型。在该模型中，利用已知的变量推测未知变量的分布称为**推断**。

假定关心的标量为Y，可观测变量集合为O，其他变量为R，那么就可以将模型分为两种：

- **生成式 考虑联合分布P(Y,R,O)**
- **判别式 考虑条件分布P(Y,R|O)**

给定观测变量，推断就是由上述分布去推测条件概率分布P(Y|O)

由于直接求解该模型的复杂度是指数级别的，因此我们需要有一套能够简洁紧凑表达变量关系的工具，其中的代表就是**概率图模型。它利用图作为标识，用结点来表示随机变量，边来表示随机变量之间的关系**，概率图主要分为两类：

- **贝叶斯网，使用有向无环图（常用于变量间存在显式因果关系的情况）**
- **马尔科夫网，使用无向图（常用于变量之间存在相关性但没有明显因果性）**

![img](https://www.biaodianfu.com/wp-content/uploads/2020/10/graphical-models.jpg)

考虑三个随机变量a,b,c，其联合概率分布为：

$$
P(a,b,c)=P(c\mid a,b)P(a,b)=P(c\mid a,b)P(b\mid a)P(a)
$$

- 对每个随机变量引入一个结点，然后为每个结点关联上式右侧对应的条件概率。
- 对于每个条件概率分布，在图中添加一个链接（箭头）：箭头的起点是条件概率的条件代表的结点。
- 对于因子P(a)，因为它不是条件概率，因此没有输入的链接。
- 如果存在一个从结点a到结点b 的链接，则称结点a是结点b的父结点，结点b是结点a的子结点。
- 可以看到，上式的左侧关于随机变量a,b,c是对称的，但是右侧不是。

实际上通过对P(a,b,c)的分解，隐式的选择了一个特定的顺序（即a,b,c）。如果选择一个不同的顺序，则得到一个不同的分解方式，因此也就得到一个不同的图的表现形式。

![img](https://www.biaodianfu.com/wp-content/uploads/2020/10/abc.png)

对于K个随机变量的联合概率分布，有：
$$
P(X_1,X_2,\cdots,X_K)=P(X_K\mid X_1,X_2,\cdots,X_{K-1})\cdots P(X_2\mid X_1)P(X_1)
$$
- 它对应于一个具有K个结点的有向图

  - 每个结点对应于公式右侧的一个条件概率分布
  - 每个结点的输入链接包含了所有的编号低于它的结点

- 这个有向图是全链接的，因为每对结点之间都存在一个链接

- **实际应用中，真正有意义的信息是图中的链接的缺失**，因为：

  - **全链接的计算量太大**
  - **链接的缺失代表了某些随机变量之间的不相关或者条件不相关**

- $$
  设结点X_i的父结点集合为\Psi_{X_i}，则所有随机变量的联合概率分布为：
  P(X_1,X_2,\cdots,X_K)=\prod_{k=1}^KP(X_k\mid \Psi_{X_k})
$$


前面讨论的是：每个结点对应于一个变量。可以很容易的推广到每个结点代表一个变量的集合（或者关联到一个向量）的情形。可以证明：如果上式右侧的每一个条件概率分布都是归一化的，则这个表示方法整体总是归一化的。

概率图模型probabilistic graphical model 就是一类**用图来表达随机变量相关关系的概率模型**：

- 用一个结点表示一个或者一组随机变量。
- 结点之间的边表示变量间的概率相关关系。

概率图描述了：联合概率分布在所有随机变量上能够分解为一组因子的乘积的形式，而每个因子只依赖于随机变量的一个子集。

![img](https://www.biaodianfu.com/wp-content/uploads/2020/10/graphical.png)

根据边的性质不同，概率图模型可以大致分为两类：

- 使用有向无环图表示随机变量间的依赖关系，称作有向图模型或者**贝叶斯网络Bayesian network**。有向图对于表达随机变量之间的**因果关系**很有用。
- 使用无向图表示随机变量间的相关关系，称作无向图模型或者**马尔可夫网络Markov network** 。无向图对于表达随机变量之间的**软限制**比较有用。

概率图模型的优点：

- 提供了一个简单的方式将概率模型的结构可视化。
- 通过观察图形，可以更深刻的认识模型的性质，包括条件独立性。
- 高级模型的推断和学习过程中的复杂计算可以利用图计算来表达，图隐式的承载了背后的数学表达式。

## 贝叶斯网络

贝叶斯网络Bayesian network借助于有向无环图来刻画特征之间的依赖关系，并使用条件概率表Conditional Probability Table : CPT 来描述特征的联合概率分布。这里每个特征代表一个随机变量，特征的具体取值就是随机变量的采样值。

## 马尔可夫随机场

根据前面的介绍，有向图模型可以将一组变量上的联合概率分布分解为局部条件概率分布的乘积。无向图模型也可以表示一个分解形式。马尔可夫随机场Markov Random Field : MRF 是一种著名的无向图模型。

现实任务中，可能只知道两个变量之间存在相关关系，但是并不知道具体怎样相关，也就无法得到变量之间的依赖关系。

- 贝叶斯网络需要知道变量之间的依赖关系，从而对依赖关系（即条件概率）建模。
- 马尔科夫随机场并不需要知道变量之间的依赖关系。它通过变量之间的联合概率分布来直接描述变量之间的关系。

如：
$$
X_1,X_2
$$
两个变量的联合概率分布为：

![img](https://www.biaodianfu.com/wp-content/uploads/2020/10/graph-1.png)

则这个分布表示：X1和X2取值相同的概率很大。事实上这里的P(⋅)就是后面介绍的**势函数**。

- **它们的总和不一定为1**。即：这个表格并未定义一个概率分布，它只是告诉我们某些配置具有更高的可能性。
- 它们并没有条件关系，它涉及到变量的联合分布的比例。

### 马尔科夫性

对结点A,B,C，若去掉结点C之后A,B分属于两个联通分支，则称结点A,B关于结点C条件独立，记作A⊥B∣C。这一概念可以推广到集合。

分离集separating set：如下图所示，若从结点集 A中的结点到结点集B中的结点都必须经过结点集C中的结点，则称结点集A和结点集B被结点集C分离，C称作分离集。

![img](https://www.biaodianfu.com/wp-content/uploads/2020/10/global-Markov-property.png)

马尔可夫随机场有三个马尔可夫性定义：全局马尔科夫性、局部马尔科夫性、成对马尔科夫性

**全局马尔可夫性**

全局马尔可夫性global Markov property：给定两个变量子集和它们的分离集，则这两个变量子集关于分离集条件独立。令结点集A、B、C对应的变量集分别为XA,XB,XC，则XA和XB在给定XC的条件下独立，记作：XA⊥XB∣XC

设结点集合A, B是在无向图G中被结点集合C分开的任意结点集合。结点集合A, B和C所对应的随机变量组分别是YA，YB和YC。全局马尔可夫性是指给定随机变量组YC条件下随机变量组YA，YB是条件独立的，即：

![img](https://www.biaodianfu.com/wp-content/uploads/2020/10/global-Markov-property-1.png)

**局部马尔可夫性**

局部马尔可夫性local Markov property：给定某变量的邻接变量，则该变量与其他变量（既不是该变量本身，也不是邻接变量）关于邻接变量条件独立。即：令V为图的结点集，n(v)为结点v在图上的邻接结点，n∗(v)=n(v)⋃{v}，则有：Xv⊥XV−n∗(v)∣Xn(v)

![img](https://www.biaodianfu.com/wp-content/uploads/2020/10/local-Markov-property.png)

设v是无向图G中任意一个结点，W是与v有边连接的所有结点，O是v, W以外的其他所有结点。分别表示随机变量Yv，以及随机变量组YW和YO。局部马尔可夫性是指在给定随机变量组YW的条件下随机变量Yv与随机变量组YO是独立的，即：

![img](https://www.biaodianfu.com/wp-content/uploads/2020/10/local-Markov-property-1.png)

**成对马尔可夫性**

成对马尔可夫性pairwise Markov property：给定两个非邻接变量，则这两个变量关于其他变量（即不是这两个变量的任何其他变量）条件独立。即：令V为图的结点集，令E为图的边集。对图中的两个结点u,v，若(u,v)∉E, 则有：Xu⊥Xv∣XV−{u,v}

![img](https://www.biaodianfu.com/wp-content/uploads/2020/10/pairwise-Markov-property.png)

设u和v是无向图G中任意两个没有边连接的结点，结点u和v分别对应随机变量Yu和Yv，其他所有结点为O，对应的随机变量组是YO。成对马尔可夫性是指给定随机变量组v的条件下随机变量Yu和Yv是条件独立的，即：

![img](https://www.biaodianfu.com/wp-content/uploads/2020/10/pairwise-Markov-property-1.png)

### 极大团

给定一张图G=(V,E)，和顶点集合的一个非空子集合C⊂V，如果C中任何两个顶点之间均有边链接，则称C为团(clique)；更进一步，若加入任何一个顶点v∈G∖C中的顶点，都使得C∪v不再是团,则称C为最大团(maximal clique)。

上述定义比较抽象，可用下图辅助理解：

- 对于团，任何两点之间都有边链接。例如，由一条边连接的两个顶点，自然成为一个团，如{A,B}，{A,C}等

- 对于最大团，如果再增加

  任何

  一个顶点，就不再成为团。

  - 对于团{A,B},还可以增加顶点C,形成团{A,B,C},该团中任何两点都有边连接。因此，{A,B}不是最大团
  - 对于团{D,E},我们看到，增加任何一个顶点，无法保证两点之间有边存在，例如，增加点C，则{C,D,E}中，不存在边(C,E)，因此{D,E}是最大团。

![img](https://www.biaodianfu.com/wp-content/uploads/2020/10/maximal-clique.png)

考虑两个结点Xi,Xj，如果它们之间不存在链接，则给定图中其他所有结点，那么这两个结点一定是条件独立的。因为这两个结点之间没有直接的路径，并且所有其他路径都通过了观测的结点。

该条件独立性表示为：



P(Xi,Xj∣X−{Xi,Xj})=P(Xi∣X−{Xi,Xj})P(Xj∣X−{Xi,Xj})



对于联合概率分布的分解，则一定要让Xi,Xj不能出现在同一个因子中，从而让属于这个图的所有可能的概率分布都满足条件独立性质。

这里引入团的概念：对于图中结点的一个子集，如果其中任意两个结点之间都有边连接，则称该结点子集为一个团clique。即：团中的结点集合是全连接的。若在一个团中加入团外的任何一个结点都不再形成团，则称该团为极大团maximal clique 。即：极大团就是不能被其他团所包含的团。显然，每个结点至少出现在一个极大团中。如下图所示：

![img](https://www.biaodianfu.com/wp-content/uploads/2020/10/clique.png)

- 所有的团有：{X1,X2},{X2,X3},{X3,X4},{X4,X2},{X1,X3},{X1,X2,X3},{X2,X3,X4}
- 极大团有：{X1,X2,X3},{X2,X3,X4}

可以将联合概率分布分解的因子定义为团中变量的函数，也称作势函数。它是定义在随机变量子集上的非负实函数，主要用于定义概率分布函数。

在马尔可夫随机场中，多个变量之间的联合概率分布能够基于团分解为多个因子的乘积，每个因子仅和一个团相关。对于n个随机变量X={X1,X2,⋯,Xn}，所有团构成的集合为C，与团Q∈C对应的变量集合记作XQ，则联合概率P(X)定义为：



P(X)=1Z∏Q∈CψQ(XQ)



其中：

- 所有团构成了整个概率图（团包含了结点和连接）， 任意两个团之间不互相包含（但是可以相交）。
- ψQ为与团Q对应的势函数，用于对团Q中的变量关系进行建模。
- Z=∑X∏Q∈CψQ(XQ)为规范化因子，确保P(X)满足概率的定义。
- 实际应用中，Z的精确计算非常困难。但是很多任务往往并不需要获得Z的精确值。

在上述P(X)计算公式中，团的数量会非常多。如：所有相互连接的两个结点都会构成一个团。这意味着有非常多的乘积项。注意到：若团Q不是极大团，则它必被一个极大团Q∗所包含。此时有：XQ⊆XQ∗。

- 于是： 随机变量集合XQ内部随机变量之间的关系不仅体现在势函数ψQ中，也体现在势函数ψQ∗中（这是根据势函数的定义得到的结论）。
- 于是： 联合概率P(X)可以基于极大团来定义。假定所有极大团构成的集合为C∗， 则有Hammersley-Clifford 定理：P(X)=1Z∗∏Q∈C∗ψQ(XQ)。其中：Z∗=∑X∏Q∈C∗ψQ(XQ) 为规范化因子，确保P(X)满足概率的定义。

通常贝叶斯网络可以将因子定义成表格形态，而马尔可夫随机场将因子定义为势函数。因为马尔可夫随机场无法将因子表格化。

假设有n个随机变量X1,X2,⋯,Xn，它们的取值都是{0,1}。假设马尔可夫随机场中它们是全连接的，则其联合概率分布需要O(2n)个参数。如果表达成表格形态，横轴表示连接的一个端点、纵轴表示连接的另一个端点，则需要O(n2)个参数。当n较大的时候，O(n2)<O(2n)，因此表格无法完全描述马尔可夫随机场的参数。

全局马尔可夫性的一个证明：

![img](https://www.biaodianfu.com/wp-content/uploads/2020/10/global-Markov-property.png)

将上图简化为如下所示：

![img](https://www.biaodianfu.com/wp-content/uploads/2020/10/xabc.png)

最大团有两个：{XA,XC},{XB,XC}，因此联合概率为：



P(XA,XB,XC)=1ZψAC(XA,XC)ψBC(XB,XC)



基于条件概率的定义有：



P(XA,XB∣XC)=P(XA,XB,XC)P(XC)



根据：



P(XC)=∑X′A∑X′BP(X′A,X′B,XC)=∑X′A∑X′B1ZψAC(X′A,XC)ψBC(X′B,XC)



将P(XC)和P(XA,XB,XC)代入，有：



P(XA,XB∣XC)=ψAC(XA,XC)ψBC(XB,XC)∑X′A∑X′BψAC(X′A,XC)ψBC(X′B,XC)=ψAC(XA,XC)∑X′AψAC(X′A,XC)⋅ψBC(XB,XC)∑X′BψBC(X′B,XC)



考虑P(XA∣XC)：



P(XA∣XC)=P(XA,XC)P(XC)=∑X′BP(XA,X′B,XC)∑X′A∑X′BP(X′A,X′B,XC)=∑X′B1ZψAC(XA,XC)ψBC(X′B,XC)∑X′A∑X′B1ZψAC(X′A,XC)ψBC(X′B,XC)=ψAC(XA,XC)∑X′BψBC(X′B,XC)(∑X′AψAC(X′A,XC))(∑X′BψBC(X′B,XC))=ψAC(XA,XC)∑X′AψAC(X′A,XC)



同理，可以推导出：



P(XB∣XC)=ψBC(XB,XC)∑X′BψBC(X′B,XC)



于是有：



P(XA,XB∣XC)=P(XA∣XC)⋅P(XB∣XC)



有向图和无向图模型都将复杂的联合分布分解为多个因子的乘积：

- 无向图模型的因子是势函数，需要全局归一化。优点是：势函数设计不受概率分布的约束，设计灵活。
- 有向图模型的因子是概率分布，不需要全局归一化。优点是：训练相对高效。

### 势函数

势函数ψQ(XQ)的作用是刻画变量集XQ中变量之间的相关关系。与有向图的联合分布的因子不同，无向图中的势函数没有一个具体的概率意义。

- 这可以使得势函数的选择具有更大的灵活性，但是也产生一个问题：对于具体任务来说，如何选择势函数。
- 可以这样理解：将势函数看做一种度量：它表示局部变量的哪种配置优于其他配置。

势函数必须是非负函数（确保概率非负），且在所偏好的变量取值上具有较大的函数值。如：



ψAC(XA,XC)={2.0,0.1,ifXA=XCotherwiseψBC(XB,XC)={0.1,1.5,ifXB=XCotherwise



该模型偏好变量XA,XC拥有相同的取值；偏好XB,XC拥有不同的取值。如果想获取较高的联合概率，则可以令XA和XC相同，且XB和XC不同。

通常使用指数函数来定义势函数：



ψQ(XQ)=e−HQ(XQ)



其中HQ(XQ)是一个定义在变量集XQ上的实值函数，称作能量函数。

指数分布被称作玻尔兹曼分布。联合概率分布被定义为势函数的乘积，因此总能量可以通过将每个最大团中的能量相加得到。这就是采取指数函数的原因，指数将势函数的乘积转换为能量函数的相加。

HQ(XQ)常见形式为：



HQ(XQ)=∑u,v∈Q,u≠vαu,vtu,v(u,v)+∑v∈Qβvsv(v)



其中：

- αu,v,βv表示系数；tu,v(u,v),sv(v)表示约束条件。
- 上式第一项考虑每一对结点之间的关系；第二项考虑单个结点。

### 图像降噪应用

马尔可夫随机场可以应用于图像问题中：

- 每个像素都表示成一个结点，相邻像素之间相互影响。
- 像素之间并不存在因果关系，它们之间的作用是对称的。因此使用无向图概率模型，而不是有向图概率模型。

马尔可夫随机场的一个应用是图像降噪。如下图所示，左侧图片为原始图像，右侧图片为添加了一定噪音（假设噪音比例不超过 10%） 的噪音图像。现在给定噪音图像，需要得到原始图像。

![img](https://www.biaodianfu.com/wp-content/uploads/2020/10/ai.png)

设随机变量Yi表示噪音图像中的像素，随机变量Xi表示原始图像中的像素。其中：

- i代表图片上的每个位置。
- Yi,Xi∈{+1,−1}。当它们取 +1 时，表示黑色；取-1 时，表示白色。

由于已知噪音图像，因此Yi的分布是已知的。原始图像未知，则Xi的分布待求解。由于噪音图像是从原始图像添加噪音而来，因此我们认为：Yi和Xi具有较强的关联。由于原始图像中，每个像素和它周围的像素值比较接近，因此Xi与它相邻的像素也存在较强的关联。因此我们假设：Xi只和它直接相邻的像素有联系（即：条件独立性质）。

因此得到一个具备局部马尔可夫性质的概率图模型。模型中具有两类团：

- 团{Xi,Yi}：原始图像的像素和噪音图像的像素
- 团{Xi,Xj}：原始图像的像素和其直接相邻的像素

这两类团就是模型中的最大团。

![img](https://www.biaodianfu.com/wp-content/uploads/2020/10/demo-1-3.png)

定义能量函数：

- 对于团{Xi,Yi}，定义能量函数：H1(Xi,Yi)=−ηXiYi。即：Xi,Yi相同时，能量较低；Xi,Yi不同时，能量较高。
- 对于团{Xi,Xj}，定义能量函数：H2(Xi,Xj)=−βXiXj。即：Xi,Xj相同时，能量较低；Xi,Xj不同时，能量较高。
- 另外对于团{Xi,Yi}，{Xi,Xj}这个整体，定义能量函数：H3(Xi)=hXi。 即：Xi较大时，能量较高； Xi较小时，能量较低。

于是得到整体的能量函数为：



H(X,Y)=h∑iXi−β∑(i,j)∈EXiXj−η∑iXiYi



其中E为原始图像的相邻像素连接得到的边。

考虑到P(X,Y)=1Z∗e−H(X,Y)，根据最大似然准则，则模型优化目标是：



minXiH(X,Y)=minXih∑iXi−β∑(i,j)∈EXiXj−η∑iXiYi



对于能量函数最小化这个最优化问题，由于每个位置的Xi都可以取2 个值{+1,−1}，因此有2N种取值策略，N为原始图像的像素数量。如果N较大，则参数的搜索空间非常巨大。实际任务中通过 ICM 算法、模拟退火算法、或者graph cuts 算法来解决这个参数搜索问题。

## 条件随机场 CRF

**生成式概率图模型是直接对联合分布进行建模**，如**隐马尔可夫模型和马尔可夫随机场都是生成式模型**。**判别式概率图模型是对条件分布进行建模**，如条件随机场Conditional Random Field : CRF。

条件随机场试图对多个随机变量（它们代表标记序列）在给定观测序列的值之后的条件概率进行建模：
$$
\mathbf X=\{  X_1, X_2,\cdots,X_n\}
$$
为观测变量序列，
$$
\mathbf Y=\{Y_1,Y_2,\cdots,Y_n\}
$$
为对应的标记变量序列。条件随机场的目标是构建条件概率模型
$$
P(\mathbf Y \mid \mathbf X)
$$
即：已知观测变量序列的条件下，标记序列发生的概率。

标记随机变量序列Y的成员之间可能具有某种结构：

- 在自然语言处理的**词性标注**任务中，**观测数据为单词序列**，**标记为对应的词性序列**（即动词、名词等词性的序列），**标记序列具有线性的序列结构**。
- 在自然语言处理的**语法分析**任务中，观测数据为**单词序列**，标记序列是**语法树**，**标记序列具有树形结构**。

令
$$
\mathcal G=<\mathbb V,\mathbb E>
$$
表示与观测变量序列X和标记变量序列Y对应的无向图，Yv表示与结点v对应的标记随机变量，n(v)表示结点v的邻接结点集。若图G中结点对应的每个变量Yv都满足马尔可夫性，即：
$$
P(Y_v\mid \mathbf X,\mathbf Y_{\mathbb V-\{v\}})=P(Y_v \mid \mathbf X,Y_{n(v)})
$$
则
$$
(\mathbf Y,\mathbf X)
$$
构成了一个条件随机场。

### 链式条件随机场

理论上讲，图G可以具有任意结构，只要能表示标记变量之间的条件独立性关系即可。但在现实应用中，尤其是对标记序列建模时，最常用的是链式结构，即链式条件随机场chain-structured CRF。

![img](https://www.biaodianfu.com/wp-content/uploads/2020/10/chain-structured-CRF.png)

如果没有特殊说明，这里讨论是基于链式条件随机场。

![img](https://www.biaodianfu.com/wp-content/uploads/2020/10/chain-structured.png)

给定观测变量序列X={X1,X2,⋯,Xn}，链式条件随机场主要包含两种关于标记变量的团：

- 单个标记变量与X构成的团：{Yi,X},i=1,2,⋯,n
- 相邻标记变量与X构成的团：{Yi−1,Yi,X},i=2,⋯,n

与马尔可夫随机场定义联合概率的方式类似，条件随机场使用势函数和团来定义条件概率{Yi−1,Yi,X},i=2,⋯,n。采用指数势函数，并引入特征函数feature function，定义条件概率：



P(Y∣X)=1Zexp(∑j=1K1∑i=1n−1λjtj(Yi,Yi+1,X,i)+∑k=1K2∑i=1nμksk(Yi,X,i))



其中：

- tj(Yi,Yi+1,X,i)：在已知观测序列情况下，两个相邻标记位置上的转移特征函数transition feature function。它刻画了相邻标记变量之间的相关关系，以及观察序列X对它们的影响。位置变量i也对势函数有影响。比如：已知观测序列情况下，相邻标记取值(代词，动词)出现在序列头部可能性较高，而(动词，代词)出现在序列头部的可能性较低。
- sk(Yi,X,i)：在已知观察序列情况下，标记位置i上的状态特征函数status feature function。它刻画了观测序列X对于标记变量的影响。位置变量i也对势函数有影响。比如：已知观测序列情况下，标记取值名词出现在序列头部可能性较高，而动词出现在序列头部的可能性较低。
- λj,μk为参数Z为规范化因子（它用于确保上式满足概率的定义）。K1为转移特征函数的个数，K2为状态特征函数的个数。

特征函数通常是实值函数，用来刻画数据的一些很可能成立或者预期成立的经验特性。一个特征函数的例子（词性标注）：



tj(Yi,Yi+1,X,i)={1,0,ifYi+1=[P],Yi=[V]andXi=“knock”otherwisesk(Yi,X,i)={1,0,ifYi=[V]andXi=“knock”otherwise



- 转移特征函数刻画的是：第i个观测值Xi为单词 “knock” 时，相应的标记Yi和Yi+1很可能分别为[V]和[P] 。
- 状态特征函数刻画的是：第i个观测值Xi为单词 “knock” 时，标记Yi很可能为[V] 。

条件随机场与马尔可夫随机场均使用团上的势函数定义概率，二者在形式上没有显著区别。条件随机场处理的是条件概率，马尔可夫随机场处理的是联合概率。

P(Y∣X)的形式类似于逻辑回归。事实上，条件随机场是逻辑回归的序列化版本。

- 逻辑回归是用于分类问题的对数线性模型
- 条件随机场是用于序列化标注的对数线性模型

### CRF 的简化形式

注意到条件随机场中的同一个特征函数在各个位置都有定义，因此可以对同一个特征在各个位置求和，将局部特征函数转化为一个全局特征函数。这样就可以将条件随机场写成权值向量和特征向量的内积形式，即条件随机场的简化形式。

设有K1个转移特征函数，K2个状态特征函数。令K=K1+K2，定义：



fk(Yi,Yi+1,X,i)={tk(Yi,Yi+1,X,i),sl(Yi,X,i),k=1,2,⋯,K1k=K1+l;l=1,2,⋯,K2



## CRF应用

### 中文分词

基本思想：每个字在构造一个特定的词语时都占据着一个确定的构词位置（即构词位）。常用的四位构词位：

![img](https://www.biaodianfu.com/wp-content/uploads/2020/10/BMES.png)

基本原理：

![img](https://www.biaodianfu.com/wp-content/uploads/2020/10/pt.png)

CRF中文分词的图结构：

![img](https://www.biaodianfu.com/wp-content/uploads/2020/10/fenxi.png)

### 命名实体识别

基于CRF的命名实体识别过程如下：

1. 词的实体标注。首先把句子进行原子切分，然后对字（词）进行实体标注。
2. 确定特征函数。接着确定特征模板。一般采用当前位置的前后n个位置上的词。‘
3. 模型训练。训练CRF模型参数Wk

CDF命名实体识别的图结构：

![img](https://www.biaodianfu.com/wp-content/uploads/2020/10/mingming.png)

### 词性标注

基本思想：判定句子中的每个词的词性并进行标注。

基本原理：

1. 对输入句子进行原子切分，得到原子切分序列
2. 对字（词）进行词性标注
3. 确定特征函数
4. 训练CRF模型参数

CRF中文词性标注的图结构：

![img](https://www.biaodianfu.com/wp-content/uploads/2020/10/cixing.png)

### CRF的概括总结

![img](https://www.biaodianfu.com/wp-content/uploads/2020/10/hc.jpg)

## CRF发展方向

- 机器学习阶段：CRF
- 深度学习阶段：BiLSTM-CRF、BiLSTM-CNN-CRF
- Attention阶段：Transformer-CRF、BERT-BiLSTM-CRF